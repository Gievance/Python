{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0fc3b7",
   "metadata": {},
   "source": [
    "     DenseNet 具有官方实现代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6b4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fa4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Sequential):\n",
    "    \"\"\"DenseBlock的基础单元\"\"\"\n",
    "    def __init__(self,num_input_features,growth_rate,bn_size,drop_rate):\n",
    "        super(DenseLayer,self).__init__()\n",
    "        self.add_module(\"norm1\",nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module(\"relu1\",nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv1\",nn.Conv2d(num_input_features,bn_size*growth_rate,kernel_size=1,stride=1,bias=False))\n",
    "        self.add_module(\"norm2\",nn.BatchNorm2d(bn_size*growth_rate))\n",
    "        self.add_module(\"relu2\",nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv2\",nn.Conv2d(bn_size*growth_rate,growth_rate,kernel_size=3,stride=1,padding=1,bias=False))\n",
    "        self.drop_rate=drop_rate\n",
    "    \n",
    "    def forward(self,x):\n",
    "        new_features=super(DenseLayer,self).foward(x)\n",
    "        if self.drop_rate>0:\n",
    "            new_features=F.dropout(new_features,p=self.drop_rate,training=self.training)\n",
    "        return torcch.cat([x,new_features],1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseBlock(nn.Sequential):\n",
    "    \"\"\"DenseBlock\"\"\"\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = DenseLayer(num_input_features+i*growth_rate, growth_rate, bn_size,\n",
    "                                drop_rate)\n",
    "            self.add_module(\"denselayer%d\" % (i+1,), layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7220ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Transition(nn.Sequential):\n",
    "    \"\"\"Transition layer between two adjacent DenseBlock\"\"\"\n",
    "    def __init__(self, num_input_feature, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module(\"norm\", nn.BatchNorm2d(num_input_feature))\n",
    "        self.add_module(\"relu\", nn.ReLU(inplace=True))\n",
    "        self.add_module(\"conv\", nn.Conv2d(num_input_feature, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module(\"pool\", nn.AvgPool2d(2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    " class DenseNet(nn.modules):\n",
    "        \"\"\"\n",
    "        DenseNet-BC model\n",
    "        \"\"\"\n",
    "        def __init__(self,growth_rate=32,block_config=(6,12,24,16),num_init_features=64,bn_size=4,compression_rat=0.5,drop_rate=0,num_classes=1000):\n",
    "            \"\"\"\n",
    "            :param growth_rate: (int) number of filters used in DenseLayer, `k` in the paper\n",
    "            :param block_config: (list of 4 ints) number of layers in each DenseBlock\n",
    "            :param num_init_features: (int) number of filters in the first Conv2d\n",
    "            :param bn_size: (int) the factor using in the bottleneck layer\n",
    "            :param compression_rate: (float) the compression rate used in Transition Layer\n",
    "            :param drop_rate: (float) the drop rate after each DenseLayer\n",
    "            :param num_classes: (int) number of classes for classification\n",
    "            \n",
    "            \"\"\"\n",
    "            super(DenseNet, self).__init__()\n",
    "            # first Conv2d\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                (\"conv0\", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                (\"norm0\", nn.BatchNorm2d(num_init_features)),\n",
    "                (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                (\"pool0\", nn.MaxPool2d(3, stride=2, padding=1))\n",
    "            ]))\n",
    "\n",
    "            # DenseBlock\n",
    "            num_features = num_init_features\n",
    "            for i, num_layers in enumerate(block_config):\n",
    "                block = DenseBlock(num_layers, num_features, bn_size, growth_rate, drop_rate)\n",
    "                self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "                num_features += num_layers*growth_rate\n",
    "                if i != len(block_config) - 1:\n",
    "                    transition = Transition(num_features, int(num_features*compression_rate))\n",
    "                    self.features.add_module(\"transition%d\" % (i + 1), transition)\n",
    "                    num_features = int(num_features * compression_rate)\n",
    "\n",
    "            # final bn+ReLU\n",
    "            self.features.add_module(\"norm5\", nn.BatchNorm2d(num_features))\n",
    "            self.features.add_module(\"relu5\", nn.ReLU(inplace=True))\n",
    "\n",
    "            # classification layer\n",
    "            self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "            # params initialization\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            features = self.features(x)\n",
    "            out = F.avg_pool2d(features, 7, stride=1).view(features.size(0), -1)\n",
    "            out = self.classifier(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f5691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607586d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac64b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432f940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
